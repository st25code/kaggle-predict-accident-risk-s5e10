# ğŸ›£ï¸ Kaggle Predict Accident Risk (Playground Series S5E10)

**Goal:** Predict the *accident risk* â€” a continuous value between **0 and 1** â€” for different types of roads.  
This project is part of **Kaggle Playground Series â€” Season 5, Episode 10**, and focuses on a clean, interpretable **regression baseline**, 
ideal for a data science portfolio.

---

## ğŸ“‚ Project Structure

```
ps_s5e10_regression_project/
â”œâ”€â”€ data/ # place train.csv, test.csv, sample_submission.csv here
â”œâ”€â”€ common/
â”‚ â””â”€â”€ prep.py # shared functions: loading, preprocessing, metrics, saving
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 1_eda/
â”‚ â”‚ â””â”€â”€ 1_eda.ipynb # EDA for regression: preview, target histogram, missing values, feature split
â”‚ â”œâ”€â”€ 2_ridge/
â”‚ â”‚ â””â”€â”€ ridge.ipynb # Ridge regression baseline
â”‚ â”œâ”€â”€ 3_random_forest/
â”‚ â”‚ â””â”€â”€ random_forest_reg.ipynb # RandomForestRegressor experiment
â”‚ â”œâ”€â”€ 4_hist_gb/
â”‚ â””â”€â”€ hist_gb_reg.ipynb # HistGradientBoostingRegressor experiment 
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ holdout_reports/ # *_holdout.json (RMSE, MAE, RÂ²)
â”‚ â”œâ”€â”€ feature_importance/ # *_perm_importance.csv (Permutation Importance)
â”‚ â””â”€â”€ submissions/ # *_reg.csv (ready Kaggle submissions)
â””â”€â”€ README.md

```

---

## ğŸ“Š Project Overview

This repository provides a reproducible workflow for predicting accident risk using regression models.  
Each notebook is self-contained, with concise code, clear markdown explanations, and auto-saving of results.

---

## ğŸ§  Models Used

- **Ridge Regression** â†’ linear baseline with scaled numeric features  
- **RandomForestRegressor** â†’ strong tree-based non-linear model  
- **HistGradientBoostingRegressor** â†’ efficient gradient boosting approach for tabular data  

**Evaluation metrics:**
- RMSE â€” Root Mean Squared Error  
- MAE â€” Mean Absolute Error  
- RÂ² â€” Coefficient of Determination  

Each model is evaluated using a simple **holdout validation (80/20 split)**.

---

## ğŸ§© Workflow

1. **EDA** â€” explore the dataset, inspect distributions, detect missing values  
2. **Model Training** â€” run each model notebook; metrics are automatically saved under `/outputs/holdout_reports`  
3. **Feature Importance** â€” computed via permutation importance on the holdout set; they are automatically saved under `/outputs/feature_importance`  
4. **Submission** â€” best model predictions are saved in `/outputs/submissions/` ready for Kaggle upload  

---

## ğŸ Next Steps

- Hyperparameter tuning for RandomForest and HGB models  
- Advanced feature engineering (ratios, polynomial terms, interaction effects)  
- Model ensembling or stacking for further accuracy improvements  

---

## ğŸ“ Kaggle Competition

ğŸ”— [Playground Series â€” Season 5, Episode 10](https://www.kaggle.com/competitions/playground-series-s5e10)

---

## ğŸ“ˆ Results Summary

| Model | RMSE | MAE | RÂ² | Notes |
|--------|------|-----|----|-------|
| Ridge Regression | â€“ | â€“ | â€“ |  |
| Random Forest Regressor | â€“ | â€“ | â€“ |  |
| HistGradientBoosting Regressor | â€“ | â€“ | â€“ |  |

*(to be filled after all models are evaluated)*

---

### ğŸ’¡ Notes

This baseline is designed to be:
- **Readable:** clear notebook structure and markdown commentary  
- **Modular:** shared preprocessing and metrics in `common/prep.py`  
- **Reproducible:** automatic saving of metrics, importances, and submissions in `/outputs/`
